{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal of this file: Go over an example of using the package Multiagent_GNN_Policies by GRASP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AirSim not installed.\n"
     ]
    }
   ],
   "source": [
    "# Import packages used in train.py and gnn_cloning.py\n",
    "from os import path\n",
    "import configparser\n",
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "import gym_flock\n",
    "import torch\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from multiagent_gnn_policies.learner.actor import Actor\n",
    "\n",
    "from multiagent_gnn_policies.learner.gnn_cloning import train_cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define an actor that doesn't \n",
    "class Actor(nn.Module):\n",
    "\n",
    "    def __init__(self, n_s, n_a, hidden_layers, k, ind_agg):\n",
    "        \"\"\"\n",
    "        The policy network is allowed to have only one aggregation operation due to communication latency, but we can\n",
    "        have any number of hidden layers to be executed by each agent individually.\n",
    "        :param n_s: number of MDP states per agent\n",
    "        :param n_a: number of MDP actions per agent\n",
    "        :param hidden_layers: list of ints that will determine the width of each hidden layer\n",
    "        :param k: aggregation filter length\n",
    "        :param ind_agg: before which MLP layer index to aggregate\n",
    "        \"\"\"\n",
    "        super(Actor, self).__init__()\n",
    "        self.k = k\n",
    "        self.n_s = n_s\n",
    "        self.n_a = n_a\n",
    "        self.layers = [n_s] + hidden_layers + [n_a]\n",
    "        self.n_layers = len(self.layers) - 1\n",
    "\n",
    "        self.ind_agg = ind_agg  # before which conv layer the aggregation happens\n",
    "\n",
    "        self.conv_layers = []\n",
    "\n",
    "        for i in range(0, self.n_layers):\n",
    "\n",
    "            if i == self.ind_agg:  # after the GSO, reduce dimensions\n",
    "                step = k\n",
    "            else:\n",
    "                step = 1\n",
    "\n",
    "            m = nn.Conv2d(in_channels=self.layers[i], out_channels=self.layers[i + 1], kernel_size=(step, 1),\n",
    "                          stride=(step, 1))\n",
    "\n",
    "            self.conv_layers.append(m)\n",
    "\n",
    "        self.conv_layers = torch.nn.ModuleList(self.conv_layers)\n",
    "\n",
    "\n",
    "    def forward(self, delay_state, delay_gso):\n",
    "        \"\"\"\n",
    "        The policy relies on delayed information from neighbors. During training, the full history for k time steps is\n",
    "        necessary.\n",
    "        :param delay_state: History of states: x_t, x_t-1,...x_t-k+1 of shape (B,K,F,N)\n",
    "        :param delay_gso: Delayed GSO: [I, A_t, A_t A_t-1, A_t ... A_t-k+1] of shape (B,K,N,N)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        batch_size = delay_state.shape[0]\n",
    "        n_agents = delay_state.shape[3]\n",
    "        assert delay_gso.shape[0] == batch_size\n",
    "        assert delay_gso.shape[2] == n_agents\n",
    "        assert delay_gso.shape[3] == n_agents\n",
    "\n",
    "        assert delay_state.shape[1] == self.k\n",
    "        assert delay_state.shape[2] == self.n_s\n",
    "        assert delay_gso.shape[1] == self.k\n",
    "\n",
    "        x = delay_state\n",
    "        x = x.permute(0, 2, 1, 3)  # now (B,F,K,N)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "\n",
    "            if i == self.ind_agg:  # aggregation only happens once - otherwise each agent operates independently\n",
    "                x = x.permute(0, 2, 1, 3)  # now (B,K,F,N)\n",
    "                x = torch.matmul(x, delay_gso)\n",
    "                x = x.permute(0, 2, 1, 3)  # now (B,F,K,N)\n",
    "\n",
    "            x = self.conv_layers[i](x)  # now (B,G,1,N)\n",
    "\n",
    "            if i < self.n_layers - 1:  # last layer - no relu\n",
    "                # x = self.layer_norms[i](x)\n",
    "                x = torch.tanh(x)\n",
    "                #x = F.relu(x)  # torch.tanh(x) #F.relu(x)\n",
    "            # else:\n",
    "            #     x = 10 * torch.tanh(x)\n",
    "\n",
    "        x = x.view((batch_size, 1, self.n_a, n_agents))  # now size (B, 1, nA, N)\n",
    "\n",
    "        # x = x.clamp(-10, 10)  # TODO these limits depend on the MDP\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define a state without delay\n",
    "class MultiAgentStateWithoutDelay(object):\n",
    "\n",
    "    def __init__(self, device, args, env_state, prev_state=None, k=None):\n",
    "        \"\"\"\n",
    "        Create the state object that keeps track of the current state and GSO and history information\n",
    "        :param device: CUDA device to use with PyTorch\n",
    "        :param args:\n",
    "        :param env_state:\n",
    "        :param prev_state:\n",
    "        \"\"\"\n",
    "        n_states = args.getint('n_states')\n",
    "        n_agents = args.getint('n_agents')\n",
    "        k = k or args.getint('k')\n",
    "        # n_states = args.n_states\n",
    "        # n_agents = args.n_agents\n",
    "        # k = args.k\n",
    "\n",
    "        # split up the state tuple\n",
    "        state_value, state_network = env_state\n",
    "\n",
    "        assert state_value.shape == (n_agents, n_states)\n",
    "        assert state_network.shape == (n_agents, n_agents)\n",
    "        assert np.sum(np.diag(state_network)) == 0  # assume no self loops\n",
    "\n",
    "        # reshape values and network to correct shape\n",
    "        state_value = state_value.transpose(1, 0)\n",
    "        state_value = state_value.reshape((1, 1, n_states, n_agents))\n",
    "        state_network = state_network.reshape((1, 1, n_agents, n_agents))\n",
    "\n",
    "        # move matrices to GPU\n",
    "        self.values = torch.Tensor(state_value).to(device)\n",
    "        self.network = torch.Tensor(state_network).to(device)\n",
    "\n",
    "        # compute current GSO - powers of the network matrix: current GSO: I, A_t, A_t^2... A_t^k-1\n",
    "        self.curr_gso = torch.zeros((1, k, n_agents, n_agents)).to(device)\n",
    "        self.curr_gso[0, 0, :, :] = torch.eye(n_agents).view((1, 1, n_agents, n_agents)).to(device)  # I\n",
    "        for k_ind in range(1, k):\n",
    "            self.curr_gso[0, k_ind, :, :] = torch.matmul(self.network, self.curr_gso[0, k_ind - 1, :, :])\n",
    "\n",
    "        # delayed GSO: I, A_t-1, ...,  A_t-1 * ... * A_t-k\n",
    "        self.delay_gso = torch.zeros((1, k, n_agents, n_agents)).to(device)\n",
    "        self.delay_gso[0, 0, :, :] = torch.eye(n_agents).view((1, 1, n_agents, n_agents)).to(device)  # I\n",
    "        if prev_state is not None and k > 1:\n",
    "            self.delay_gso[0, 1:k, :, :] = torch.matmul(self.network, prev_state.delay_gso[0, 0:k - 1, :, :])\n",
    "\n",
    "        # delayed x values x_t, x_t-1,..., x_t-k\n",
    "        self.delay_state = torch.zeros((1, k, n_states, n_agents)).to(device)\n",
    "        self.delay_state[0, 0, :, :] = self.values\n",
    "        if prev_state is not None and k > 1:\n",
    "            self.delay_state[0, 1:k, :, :] = prev_state.delay_state[0, 0:k - 1, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions from train.py\n",
    "def run_experiment(args):\n",
    "    # initialize gym env\n",
    "    env_name = args.get('env')\n",
    "    env = gym.make(env_name)\n",
    "\n",
    "    if isinstance(env.env, gym_flock.envs.FlockingRelativeEnv):\n",
    "        env.env.params_from_cfg(args)\n",
    "\n",
    "    # use seed\n",
    "    seed = args.getint('seed')\n",
    "    env.seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # initialize params tuple\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    stats = train_cloning(env, args, device)\n",
    "\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward\n"
     ]
    }
   ],
   "source": [
    "# main() equivalent from train.py\n",
    "fname = 'multiagent_gnn_policies/cfg/cloning.cfg' #sys.argv[1]\n",
    "config_file = path.join(path.abspath(''), fname) # For Jupyter\n",
    "# config_file = path.join(path.dirname(__file__), fname)\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file)\n",
    "\n",
    "printed_header = False\n",
    "\n",
    "if config.sections():\n",
    "    for section_name in config.sections():\n",
    "        if not printed_header:\n",
    "            print(config[section_name].get('header'))\n",
    "            printed_header = True\n",
    "\n",
    "        stats = run_experiment(config[section_name])\n",
    "        print(section_name + \", \" + str(stats['mean']) + \", \" + str(stats['std']))\n",
    "else:\n",
    "    val = run_experiment(config[config.default_section])\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zz/Documents/GT20F/7000/multiagent_gnn_policies/cfg/cloning.cfg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/zz/Documents/GT20F/7000/GNN_experiments'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/zz/Documents/GT20F/7000', 'multiagent_gnn_policies/cfg/cloning.cfg')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.dirname(__file__), fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
